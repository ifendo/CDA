[["index.html", "Clinical Data Analysis Chapter 1 Prerequisites", " Clinical Data Analysis Jie Wang 2020-12-24 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandocs Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. "],["intro.html", "Chapter 2 Introduction 2.1 Discrete Distributions 2.2 Continuous Distributions 2.3 One-Sample t-Test 2.4 Paired-t test 2.5 Two-sample t-Test 2.6 Reference table and figure", " Chapter 2 Introduction 2.1 Discrete Distributions The binomial distribution is, perhaps, the most commonly used discrete distribution in clinical biostatistics. Other commonly used discrete distributions include the poisson and the hypergeometric distributions. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! 2.2 Continuous Distributions If a random variable can take any value within an interval or continuum, it is called a continuous random variable. Continuous distributions are most conveniently approximated by functions of the random variableX, such as PX: PX = 2 * x for (0 &lt; x &lt; 1) The normal probability distribution is the most commonly used continuous distribution in clinical research statistics. Many naturally occurring phenomena follow the normal distribution, which can be explained by a powerful result from probability theory known as Central Limit Theorem The Central Limit Theorem states that, regardless of the distribution of measurements, sums and averages of a large number of like measurements tend to follow the normal distribution. Other common continuous distributions are the exponential distribution, the chi-square distribution, the F-distribution, and the Student t-distribution. 2.3 One-Sample t-Test The one-sample t-test is used to infer whether an unknown population mean diffs from a hypothesized value. The test is based on a simple of n measurements from the population. The t-distribution is symmetric and bell-shaped, like the normal distribution, but has heavier tails, meaning that it is more prone to producing values that fall far from its mean. The main difference between the Z-test and the t-test is that the Z-statistic is based on a known standard deviation, while the t-statistic uses the sample standard deviation as an estimate of sigma. A sample of n data points, y1, y2, , yn is randomly selected from a normally distributed population with unknown mean, mu. This mean is estimated by the sample mean, y hat. You hypothesize the mean to be some value, mu zero. The greater the deviation between y hat and mu zero, the greater the evidence that the hypothesis is untrue. The test statistic is a function of this deviation, standardized by the standard error of y hat, namely s / sqrt(n). 2.3.1 SAS example according to history data, the BMI was 28.4. A new study collects some data below and wants to know if the BMI from this sample is consistent with previous findings. data bmi; input patno wt_kg ht_cm; bmi=wt_kg / ((ht_cm / 100) ** 2); cards; 1 101.7 178 2 97.1 170 3 114.2 191 4 101.9 179 5 93.1 182 6 108.1 177 7 85.0 184 8 89.1 182 9 95.8 179 10 97.8 183 11 78.7 . 12 77.5 172 13 102.8 183 14 81.1 169 15 102.1 177 16 112.1 180 17 89.7 184 ; run; proc ttest h0=28.4 data=bmi; var bmi; run; /* test for normality can be carried in SAS using normal option in proc univariate*/ proc univariate normal data=bmi; var bmi; run; 2.3.2 Test of normality: Shapiro - Wilk test The Shapiro - Wilk test is a test of normality in in frequentist statistics. It was published in 1965 by Samuel Sanford Shapiro and Martin Wilk. The null-hypothesis of this test is that the population is normally distributed. Thus, if the p value is less than the chosen alpha level, then the null hypothesis is rejected and there is evidence that the data tested are not normally distributed. On the other hand, if the p value is greater than the chosen alpha level, then the null hypothesis (that the data came from a normally distributed population) can not be rejected 2.4 Paired-t test data obese; input subj wtpre wtpst @@; wtloss=wtpre - wtpst; cards; 1 165 160 2 202 200 3 256 259 4 155 156 5 135 134 6 175 162 7 180 187 8 174 172 9 136 138 10 168 162 11 207 197 12 155 155 13 220 205 14 163 153 15 159 150 16 253 255 17 138 128 18 287 280 19 177 171 20 181 170 21 148 154 22 167 170 23 190 180 24 165 154 25 155 150 26 153 145 27 205 206 28 186 184 29 178 166 30 129 132 31 125 127 32 165 169 33 156 158 34 170 161 35 145 152 ; run; proc ttest data=obese; paired wtpre*wtpst; run; 2.5 Two-sample t-Test The two-sample t-test is used to compare the means of two independent populations. The unknown means, mu1 and mu2, are estimated by the sample means, y1 hat and y2 hat. **The greater the difference between the sample means, the greater the evidence that the hypothesis of equality of population means is untrue. /* placebo group: A, active group: B, measurements are scores at Week 0 and Week 6*/ data scores; input patno trtgrp $ week0 week6 @@; chg = week6 - week0; if chg eq . then delete; cards; 101 A 1.35 . 103 A 3.22 3.55 106 A 2.78 3.15 108 A 2.45 2.30 109 A 1.84 2.37 110 A 2.81 3.20 113 A 1.90 2.65 116 A 3.00 3.96 118 A 2.25 2.97 120 A 2.86 2.28 121 A 1.56 2.67 124 A 2.66 3.76 102 P 3.01 3.90 104 P 2.24 3.01 105 P 2.25 2.47 107 P 1.65 1.99 111 P 1.95 . 112 P 3.05 3.26 114 P 2.75 2.55 115 P 1.60 2.20 117 P 2.77 2.56 119 P 2.06 2.90 122 P 1.71 . 123 P 3.54 2.92 ; run; proc means data=scores mean std n t prt; /* t prt to request the within group one-sampel t-test*/ class trtgrp; var week0 week6 chg; run; /* two-sample t-test*/ proc ttest data=scores; class trtgrp; var chg; run; The assumption of equal variances can be tested using the F-test. An F-test generally arises as a ratio of variances. When the hypothesis of equal variances is true, the ratio of sample variances should be about 1. The probability distribution of this ratio is known as the F-distribution (which is widely used in the analysis of variance) If the hypothesis of equal variances is rejected, the t-test might give erroneous results. In such cases, a modified version of the t-test proposed by Satterthwaite is often used. 2.6 Reference table and figure Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Walker and Shostak 2010). References "],["one-way-anova.html", "Chapter 3 One-Way ANOVA 3.1 SAS example 3.2 Sample Result", " Chapter 3 One-Way ANOVA One-way ANOVA(analysis of variance) is used to simultaneously compare two or more group means based on independent samples from each group. The bigger the variation among sample group means relative to the variation of individual measurements within the groups, the greater the evidence that the hypothesis of equal group means is untrue. The ANOVA methods seek to identify sources of variation for each measurements, and separate the total variability into components: total variability: sum of squared deviations of each measurements from the overall mean. sum of squares due to suspected sources of variation (often called model sum of squares) sum of squares due to error The error variability includes such things as measurement error, normal variation due to repeated sampling The sources that can be identified and controlled are included in the model SS. An ANOVA is conducted using F-tests that are constructed from the ratio of between-group to within-group variance estimates. Under the hypothesis of no group effect, the variation among groups is just another measure of patient-to-patient variability, so their ratio should be about 1. The one-way ANOVA has one main effect or grouping factor with two or more levels(e.g. typically treatment effect). The two-way ANOVA has two main effects, usually a grouping or treatment factor and a blocking factor(such as Gender, Study Center) In most types of ANOVA used in clinical trials, the primary question the researcher wants to answer is whether there are any differences among the group population means based on the sample data. The null hypothesis to be tested is there is no Group effect or, equivalently, the mean responses are the same for all groups. The alternative hypothesis is that the Group effect is important or, equivalently, the Group means differ for at least one pair of groups. The one-way ANOVA involves a straightforward comparison of the between-group variation to the within-group variation. An ANOVA that involves blocking factors or covariates seeks to refine treatment comparison by factoring out extraneous variation due to known sources. 3.1 SAS example data scores; input patno dosegrp $ score @@; cards; 101 LO 21 104 LO 18 106 LO 19 110 LO . 112 LO 28 116 LO 22 120 LO 30 121 LO 27 124 LO 28 125 LO 19 130 LO 23 136 LO 22 137 LO 20 141 LO 19 143 LO 26 148 LO 35 152 LO . 103 HI 16 105 HI 21 190 HI 31 111 HI 25 113 HI 23 119 HI 25 123 HI 18 127 HI 20 128 HI 18 131 HI 16 135 HI 24 138 HI 22 140 HI 21 142 HI 16 146 HI 33 150 HI 21 151 HI 17 102 PB 22 107 PB 26 108 PB 29 114 PB 19 115 PB . 117 PB 33 118 PB 37 122 PB 25 126 PB 28 129 PB 26 132 PB . 133 PB 31 134 PB 27 139 PB 30 144 PB 25 145 PB 22 147 PB 36 149 PB 32 ; run; proc sort data=scores; by dosegrp; run; proc means data=scores mean std n; by dosegrp; var score; run; proc glm data=scores plots=boxplot; class dosegrp; /*model factor must also be specified in the CLASS statement to indicate it is a classification factor rather than a numeric covariate*/ model score=dosegrp; /* response variable on the left, model factors on the right*/ means dosegrp / hovtest t dunnett (&#39;PB&#39;); contrast &#39;Active vs . Placebo&#39; dosegrp 0.5 0.5 -1; run; quit; 3.2 Sample Result The p-value of 0.0023 (&lt;0.05) indicates that the mean scores differ significantly among Dose Groups. With a significant Dose Group effect, the next question is which group or groups contribute to that difference. The means statment is used to obtain multiple comparison results using both the pairwise t-test and Dunnetts test: both of thse methods reveal significant differences between each active group and placebo. 3.2.1 Pairwise t-test 3.2.2 Dunnetts test 3.2.3 side-by-side A one-way ANOVA requires the assumptions of: + normally distributed data + independent samples from each group + variance homogeneity among groups A number of formal tests, such as Levenes test or Bartletts test, can be used to test for homogeneity of variances. In SAS, we simply include the HOVTEST option in the means statement to run Levenes test: the p-value for equal variances in the example is 0.998. This, along with the box plot, indicates no differences among the groups in variability. In the event that equal variances among groups is not a plausible assumption, we can conduct an approximate test, known as Welchs test, for comparing the group means. We can do this like means dosegrp/welch. Welchs test** is analogous to the Satterthwaites adjustment used in two-sample t-test. 3.2.4 Some notes When comparing more than 2 means, a significant F-test indicates that at least one pair of means differs, but which pair is not identified by ANOVA If null hypothesis of equal means is rejected, further analysis must be undertaken to investigate where the differences lie. all-pairwise tests: similar to two-sample t-test, but rather that using the pooled standard deviation of only the two groups being compared, the pooled standard deviation of all groups is used. Use ** means dosegrp / t** (t option) compares treatment means with a control group is called Dunnetts test contrast statement: customized comparisons among combinations of the group means can be made. This is done by testing whether specific linear combinations of the group means differ from 0 By using the estimate statement in SAS following the model statement, we can obtain the mean and standard error of the group mean proc glm data=scores; class dosegrp; model score=dosegrp; /*obtain mean and standard error for each group*/ estimate &quot;Hi Dose Group&quot; intercept 1 dosegrp 1 0 0; /*intercept term corresponding to overall mean*/ estimate &quot;Lo Dose Group&quot; intercept 1 dosegrp 0 1 0; estimate &quot;Placebo Dose Group&quot; intercept 1 dosegrp 0 0 1; /*obtain mean difference and standard error*/ estimate &quot;Lo Group vs. Placebo&quot; dosegrp 0 1 -1; run; quit; If there are only two groups, the p-value for Group effect using an ANOVA is the same as that of a two-sample t-test. The F- and t-distribution enjoy the relationship that, with 1 upper degree of freedom, the F-statistic is the square of the t-statistic. For one-way ANOVA, all four types of sums of squares are identical. "],["two-way-anova.html", "Chapter 4 Two-Way ANOVA 4.1 SAS example 4.2 Sample Result 4.3 Least Squares Mean (LS-mean) 4.4 Unbalanced Two-way ANOVA 4.5 Some notes", " Chapter 4 Two-Way ANOVA The two-way ANOVA is a method for simultaneously analyzing two factors that affect a response. 4.1 SAS example data hgbds; input trt $ type $ patno hgbch @@; datalines; ACT C 1 1.7 ACT C 3 -0.2 ACT C 6 1.7 ACT C 7 2.3 ACT C 10 2.7 ACT C 12 0.4 ACT C 13 1.3 ACT C 15 0.6 ACT P 22 2.7 ACT P 24 1.6 ACT P 26 2.5 ACT P 28 0.5 ACT P 29 2.6 ACT P 31 3.7 ACT P 34 2.7 ACT P 36 1.3 ACT R 42 -0.3 ACT R 45 1.9 ACT R 46 1.7 ACT R 47 0.5 ACT R 49 2.1 ACT R 51 -0.4 ACT R 52 0.1 ACT R 54 1.0 PBO C 2 2.3 PBO C 4 1.2 PBO C 5 -0.6 PBO C 8 1.3 PBO C 9 -1.1 PBO C 11 1.6 PBO C 14 -0.2 PBO C 16 1.9 PBO P 21 0.6 PBO P 23 1.7 PBO P 25 0.8 PBO P 27 1.7 PBO P 30 1.4 PBO P 32 0.7 PBO P 33 0.8 PBO P 35 1.5 PBO R 41 1.6 PBO R 43 -2.2 PBO R 44 1.9 PBO R 48 -1.6 PBO R 50 0.8 PBO R 53 -0.9 PBO R 55 1.5 PBO R 56 2.1 ; run; proc format; value $typfmt &#39;C&#39; = &#39;CERVICAL &#39; &#39;P&#39; = &#39;PROSTATE &#39; &#39;R&#39; = &#39;COLORECTAL&#39; ; run; proc glm data=hgbds; class trt type; model hgbch = trt type trt*type /ss3; lsmeans type / pdiff stderr t lines; format type $typfmt.; run; quit; 4.2 Sample Result 4.2.1 Some notes There is significant difference in treatment effect (p=0.0491) There is also significant difference among Cancer Types (p=0.0376), but because there are more than 2 levels of this effect, further analysis are needed to determine where the differences exist. To perform pairwise t-tests for multiple comparisons, we can include the lsmeans statment with T option after the model statment. mean hemoglobin response differs significantly between the PROSTATE and COLORECTAL Cancer Types 4.3 Least Squares Mean (LS-mean) 4.4 Unbalanced Two-way ANOVA data memry; input dose $ center $ y @@; datalines; 0 A 6 0 A 5 0 A 6 0 A 8 0 A 3 0 A 4 0 A 5 0 A 6 0 A 5 0 A 5 0 A 7 0 A 8 0 B 7 0 B 4 0 B 7 0 B 6 0 B 7 0 B 8 0 B 5 0 B 9 0 B 11 0 B 4 0 B 7 30 A 8 30 A 12 30 A 7 30 A 8 30 A 6 30 A 9 30 A 6 30 A 11 30 B 5 30 B 6 30 B 6 30 B 5 30 B 3 30 B 8 30 B 6 30 B 9 30 B 11 30 B 5 60 A 11 60 A 7 60 A 7 60 A 11 60 A 9 60 A 10 60 A 12 60 A 9 60 A 15 60 B 9 60 B 12 60 B 13 60 B 9 60 B 13 60 B 12 60 B 14 60 B 15 60 B 12 ; run; proc glm data=memry; class dose center; model y=dose center dose*center; lsmeans dose/pdiff stderr; run; quit; 4.5 Some notes From the SAS outputs, we can conclude that a difference exists between the 60 mg dose and the placebo, but the overall efficacy of the 30 mg dose is in question. 4.5.1 Mixed effects There are two types of effects that can be used in an ANOVA model, the fixed effect and random effect. Fixed: pre-specified levels, with the goal of comparing specific levels of that effect, e.g. treatment group Random: blocking factor in a two-way ANOVA can be either fixed or random. e.g. Study Center is frequently considered a random effect since the centers often represent a sample from a large number of centers available to conduct the study. /* study center as a random effect */ proc glm data=memry; class dose center; model y=dose center dose*center; random center dose*center; test h=dose e=dose*center; lsmeans dose /pdiff stderr; run; quit; 4.5.2 Using Proc Mixed When using SAS, Proc Mixed is preferable to Proc GLM in many situations. proc mixed data=memry; class dose center; model y=dose center dose*center; lsmeans dose*center /diff; run; quit; /*study center is random effect*/ /*this mixed model analysis enables us to make inferences about the Dose effect that applies to the entire population without concern for the levels of random effects*/ proc mixed data=memry; class dose center; model y=dose; /*study center not included here*/ random center dose*center; lsmeans dose /diff; run; quit; In SAS, Type III corresponds to the method of weighted squares of means and is often the method of choice for the analysis of clinical data. "],["repeated-measures.html", "Chapter 5 Repeated Measures 5.1 Introduction 5.2 SAS example 5.3 Example from trial", " Chapter 5 Repeated Measures 5.1 Introduction Repeated measures refer to multiple measurements taken from the same experimental unit. These repeated response measurements can be used to characterize a response profile over time. One of the main question the researcher asks is whether the mean response profile for one treatment group is the same as for another treatment group or a placebo group. More commonly used now are approaches based on general linear modeling techniques. 5.2 SAS example data arthr; input vacgrp $ pat mo1 mo2 mo3 ; datalines; ACT 101 6 3 0 ACT 103 7 3 1 ACT 104 4 1 2 ACT 107 8 4 3 PBO 102 6 5 5 PBO 105 9 4 6 PBO 106 5 3 4 PBO 108 6 2 3 ; run; data discom; set arthr; keep vacgrp pat visit score; score = mo1; visit = 1; output; score = mo2; visit = 2; output; score = mo3; visit = 3; output; run; title3 &quot;PROC MIXED with Unstructured Covariance&quot;; proc mixed data = discom; class vacgrp pat visit; model score = vacgrp visit vacgrp*visit; repeated visit / subject=pat(vacgrp) type=un; run; quit; 5.3 Example from trial 5.3.1 Sample MMRM program ods output Estimates=_mmrm_est LSMeans=_lsmeans_est; /* for Week 16*/ proc mixed data=_dsn(where=(avisitn&gt;20000)); class trt01p(ref=&quot;Placebo&quot;) avisitn dmdstrat crpstrat usubjid; model chg=trt01p avisitn base dmdstrat crpstrat trt01p*avisitn/noint cl ddfm=kr outpm=resid_mmrm vciry; repeated avisitn/subject=usubjid type=un; lsmeans trt01p*avisitn/cl; estimate &quot;100q4w vs placebo&quot; trt01p 1 0 -1 trt01p*avisitn 1 0 0 0 -1 0/e cl; estimate &quot;100q8w vs placebo&quot; trt01p 0 1 -1 trt01p*avisitn 0 0 1 0 -1 0/e cl; run; /* for Week 24*/ proc mixed data=_dsn(where=(avisitn&gt;20000)); class trt01p(ref=&quot;Placebo&quot;) avisitn dmdstrat crpstrat usubjid; model chg=trt01p avisitn base dmdstrat crpstrat trt01p*avisitn/noint cl ddfm=kr outpm=resid_mmrm vciry; repeated avisitn/subject=usubjid type=un; lsmeans trt01p*avisitn/cl; estimate &quot;100q4w vs placebo&quot; trt01p 1 0 -1 trt01p*avisitn 0 1 0 0 0 -1/e cl; estimate &quot;100q8w vs placebo&quot; trt01p 0 1 -1 trt01p*avisitn 0 0 0 1 0 -1/e cl; run; 5.3.2 Sample MMRM output "],["linear-regression.html", "Chapter 6 Linear Regression 6.1 Introduction 6.2 Some notes", " Chapter 6 Linear Regression 6.1 Introduction Given a number of observed values of a normally distributed response variable(y1, y2, , yn), the mean, y hat, represents the estimate of a future response. The idea behind regression analysis is to improve this estimate by using the value of some related factor, X. data angina; input pat x_dur y_impr @@; datalines; 1 1 40 2 1 90 3 3 30 4 2 30 5 1 80 6 5 60 7 1 10 8 4 -10 9 2 50 10 6 40 11 1 60 12 4 0 13 2 50 14 2 110 15 3 20 16 3 70 17 5 -30 18 3 20 19 1 40 20 6 0 ; run; proc sort data=angina; by x_dur y_impr; run; proc glm data=angina; model y_impr = x_dur / p clm ss1; /* p: predicted values, CLM: confidence intervals*/ run; quit; 6.2 Some notes "],["analysis-of-covariance.html", "Chapter 7 Analysis of Covariance 7.1 Introduction 7.2 SAS Example", " Chapter 7 Analysis of Covariance 7.1 Introduction Analysis of covariance (ANCOVA) provides a method for comparing response means among two or more groups adjusted for a quantitative concomitant variable, or covariate, thought to influence the response. The attention here is confined to cases in which the response, y, might be linearly related to the covariate, x. ANCOVA combines regression and ANOVA methods by fitting simple linear regression models within each group and comparing regressions among groups. Some examples: + comparing cholesterol levels (y) between a treated group and a reference group adjusted for age (x, in years) + comparing scar healing (y) between conventional and laser surgery adjusted for excision size (x, in mm) + comparing exercise tolerance (y) in 3 dose levels of a treatment used for angina patients adjusted for smoking habits (x, in cigarettes/day). ANCOVA can often increase the precision of comparisons of the group means by including the covariate, x, as a source of variation, thereby decreasing the estimated error variance. ANCOVA is especially useful when the values of the covariate differ among the groups. When this occurs and the response is linearly related to the covariate, covariance adjustments can lead to markedly different conclusions than those obtained using the unadjusted ANOVA methods. 7.2 SAS Example data tri; input trt $ pat hgba1c trichg @@; datalines; FIB 2 7.0 5 FIB 4 6.0 10 FIB 7 7.1 -5 FIB 8 8.6 -20 FIB 11 6.3 0 FIB 13 7.5 -15 FIB 16 6.6 10 FIB 17 7.4 -10 FIB 19 5.3 20 FIB 21 6.5 -15 FIB 23 6.2 5 FIB 24 7.8 0 FIB 27 8.5 -40 FIB 28 9.2 -25 FIB 30 5.0 25 FIB 33 7.0 -10 GEM 1 5.1 10 GEM 3 6.0 15 GEM 5 7.2 -15 GEM 6 6.4 5 GEM 9 5.5 10 GEM 10 6.0 -15 GEM 12 5.6 -5 GEM 14 5.5 -10 GEM 15 6.7 -20 GEM 18 8.6 -40 GEM 20 6.4 -5 GEM 22 6.0 -10 GEM 25 9.3 -40 GEM 26 8.5 -20 GEM 29 7.9 -35 GEM 31 7.4 0 GEM 32 5.0 0 GEM 34 6.5 -10 ; run; proc sort data=tri; by trt hgba1c trichg; run; proc means data=tri mean std n; by trt; var hgba1c trichg; run; /* use hgba1c as covariate */ proc glm data=tri; class trt; model trichg = trt hgba1c / solution; /* solution: obtains the estimates for the regression equations*/ lsmeans trt/pdiff stderr cl; run; quit; /* compare groups with ANOVA, ignoring the covariate */ proc glm data=tri; class trt; model trichg = trt/ss3; run; quit; "],["the-binomial-test.html", "Chapter 8 The Binomial Test 8.1 Overview 8.2 Normal Approximation 8.3 A proc freq example 8.4 The Chi-Square Test 8.5 CMH 8.6 Fishers exact test", " Chapter 8 The Binomial Test 8.1 Overview The binomial test is used to make inferences about a proportion or response rate based on a series of independent observations, each resulting in one of two possible mutually exclusive outcomes, such as: + response to treatment vs. no response + cure or no cure + survival or death + event vs non-event (in general) The total number of events in n observations, X, follows the binomial probability distribution. Intuitively, the sample proportion, X/n, would be a good estimate of the unknown population proportion, p. Statistically, it is the best estimate. You want to determine whether the population proportion, p, differs from a hypothesized value, p0. If the unknown proportion, p, equals p0, then the estimated proportion, X/n, should be close to p0, i.e., X should be close to n * p0. When p differs from p0, X might be much larger or smaller than n * p0. SAS function, probbnml() can be used to determine XL and XU (lower limit and upper limit) 8.2 Normal Approximation For larger values of n and non-extreme values of p, a binomial response, X, can be approximated by a normal distribution with mean n * p and variance n * p * (1-p). This approximation improves as n gets larger or as p gets closer to 0.5 8.3 A proc freq example data acr20; input patient $ avalc $ @@; cards; 1 Yes 2 No 3 Yes 4 No 5 Yes 6 Yes 7 No 8 Yes 9 No 10 No 11 Yes 12 No 13 Yes 14 No 15 Yes 16 No 17 No 18 Yes 19 Yes 20 No 21 Yes 22 Yes 23 No 24 Yes 25 Yes ; run; data acr20a; set acr20; avalc=ifc(avalc=&quot;Yes&quot;, &quot;1Yes&quot;, &quot;2No&quot;); run; proc freq data=acr20a; tables avalc / binomialc (p = 0.4) alpha=0.05; exact binomial; title1 &quot;Binomial Test&quot;; run; 8.3.1 A real example from trial 8.3.1.1 proc freq to calculate Wald CI data resp; input avisitn avisit $ trt01pn avalc $ count; cards; 20052 Week_52 1 N 124 20052 Week_52 1 Y 112 20052 Week_52 2 N 97 20052 Week_52 2 Y 131 20052 Week_52 3 N 94 20052 Week_52 3 Y 134 20068 Week_68 1 N 113 20068 Week_68 1 Y 123 20068 Week_68 2 N 91 20068 Week_68 2 Y 137 20068 Week_68 3 N 85 20068 Week_68 3 Y 143 ; run; proc sort data=resp; by avisitn avisit trt01pn; run; ods output BinomialCLs=bincl; proc freq data=resp; by avisitn avisit trt01pn; table avalc/binomial(level = &quot;Y&quot; CL=WALD(CORRECT)); weight count; run; data resp2; set bincl; if proportion not in (0,.) then percent = round(proportion * 100, .1); else percent=0; if lowercl not in (0,.) then lowercl = round(lowercl * 100, .1); else lowercl=0; if uppercl not in (0,.) then uppercl = round(uppercl * 100, .1); else uppercl=0; run; SAS doc 8.4 The Chi-Square Test The chi-square test is used to compare two independent binomial proportions, p1, and p2. Often, you want to compare the response rates between a treated group and a parallel control group. The chi-square test is an approximate test, which may be used when the normal approximation to the binomial distribution is valid. 8.5 CMH Example: TEFDACT08 from PSA3002 Week 24 8.6 Fishers exact test Example: TEFDAPSA02 from PSA3002 Week 24 "]]
